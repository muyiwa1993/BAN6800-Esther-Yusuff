{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96619e44-2508-460c-b4e5-67810580f897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to C:\\Users\\ACER\\Documents\\BAN6800\\cleaned_churn_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\ACER\\Documents\\BAN6800\\churn_80_airtelnigeria.csv\")\n",
    "\n",
    "# Step 1: Check for missing or irregular values\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.fillna(0, inplace=True)  # Assuming missing numeric values can be treated as 0 for now\n",
    "\n",
    "# Step 2: Standardize data types\n",
    "categorical_columns = ['Region', 'Roaming Plan', 'Data Plan']\n",
    "bool_columns = ['Churn (Inactive >30 Days)']\n",
    "data[bool_columns] = data[bool_columns].astype(bool)\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_columns = pd.DataFrame(encoder.fit_transform(data[categorical_columns]),\n",
    "                               columns=encoder.get_feature_names_out(categorical_columns),\n",
    "                               index=data.index)\n",
    "data = pd.concat([data.drop(columns=categorical_columns), encoded_columns], axis=1)\n",
    "\n",
    "# Step 4: Feature Engineering (if needed)\n",
    "data['Total Data Usage (MB)'] = (data['Total Day Data (MB)'] + \n",
    "                                 data['Total Evening Data (MB)'] + \n",
    "                                 data['Total Night Data (MB)'] + \n",
    "                                 data['Total Roaming Data (MB)'])\n",
    "\n",
    "# Step 5: Scaling numerical features\n",
    "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Step 6: Outlier detection (basic z-score based removal)\n",
    "z_scores = np.abs((data[numerical_columns] - data[numerical_columns].mean()) / data[numerical_columns].std())\n",
    "data = data[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Save the cleaned and processed dataset\n",
    "cleaned_file_path = r\"C:\\Users\\ACER\\Documents\\BAN6800\\cleaned_churn_data.csv\"\n",
    "data.to_csv(cleaned_file_path, index=False, header=True)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4578cc4e-7f82-49eb-a549-9f38d422e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before outlier removal: 2666\n",
      "Rows after outlier removal: 2666\n",
      "Cleaned dataset saved to C:\\Users\\ACER\\Documents\\BAN6800\\cleaned_churn_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\ACER\\Documents\\BAN6800\\churn_80_airtelnigeria.csv\")\n",
    "\n",
    "# Step 1: Check for missing or irregular values\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.fillna(0, inplace=True)  # Assuming missing numeric values can be treated as 0 for now\n",
    "\n",
    "# Step 2: Standardize data types\n",
    "categorical_columns = ['Region', 'Roaming Plan', 'Data Plan']\n",
    "bool_columns = ['Churn (Inactive >30 Days)']\n",
    "data[bool_columns] = data[bool_columns].astype(bool)\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_columns = pd.DataFrame(encoder.fit_transform(data[categorical_columns]),\n",
    "                               columns=encoder.get_feature_names_out(categorical_columns),\n",
    "                               index=data.index)\n",
    "data = pd.concat([data.drop(columns=categorical_columns), encoded_columns], axis=1)\n",
    "\n",
    "# Step 4: Feature Engineering (if needed)\n",
    "data['Total Data Usage (MB)'] = (data['Total Day Data (MB)'] + \n",
    "                                 data['Total Evening Data (MB)'] + \n",
    "                                 data['Total Night Data (MB)'] + \n",
    "                                 data['Total Roaming Data (MB)'])\n",
    "\n",
    "# Step 5: Scaling numerical features\n",
    "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Step 6: Outlier detection (adjusted logic)\n",
    "z_scores = np.abs((data[numerical_columns] - data[numerical_columns].mean()) / data[numerical_columns].std())\n",
    "outlier_threshold = 0.5  # Allow up to 50% of columns in a row to be outliers\n",
    "outlier_mask = (z_scores > 3).sum(axis=1) / len(numerical_columns) <= outlier_threshold\n",
    "print(f\"Rows before outlier removal: {data.shape[0]}\")\n",
    "data = data[outlier_mask]\n",
    "print(f\"Rows after outlier removal: {data.shape[0]}\")\n",
    "\n",
    "# Save the cleaned and processed dataset\n",
    "cleaned_file_path = r\"C:\\Users\\ACER\\Documents\\BAN6800\\cleaned_churn_data.csv\"\n",
    "data.to_csv(cleaned_file_path, index=False, header=True)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae2202-29fc-43ad-bc60-d0bb536b1d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
